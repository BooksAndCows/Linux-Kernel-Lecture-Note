# 5강\(by wiseCow\)

---

## 

## Kernel Thread \(KT\)

---

4강에서 다뤘던 내용들을 잠시 떠올려보자. 스레드\(Thread\)가 있고 프로세스\(Process\)가 있었다. 프로세스는 부모의 것\(Task basic info + files, fs, tty, mm, signals\)을 전부 그대로 복사한 것\(heavy-weight creation\)이고, 반대로 최소한으로 복사\(light-weight creation\)한 것이 스레드이다.

또한 커널은 메모리 상주 프로그램\(memory resident program\)이다. main\( \)함수가 있는 평범한 프로그램의 특성과 부팅할 때 부터 메모리에 올라와서 컴퓨터의 전원을 완전히 차단할 때까지 메모리에 상주한다는 특성을 함께 가지고 있다. 여기까지 떠올렸다면 이제 아래 템플릿을 보면서 오늘 다룰 주제 중 하나인 커널 스레드를 살펴보자.

![](/assets/Chapter 5_0.PNG)

위 템플릿의 우측 보라색으로 칠해진 부분은 커널영역을 의미한다. 컴퓨터가 맨 처음 부팅\(booting\)하면 분명 커널의 main\( \)부터 실행이 될 것이다. 그러다가 커널 프로세스 내에서 시스템 콜 clone\( \)을 호출하게 되면 자식 프로세스가 생기는데, 이때 부모\(parent\)가 가르치는 PC\(Program Counter\)와 자식\(child\)이 가리키는 PC는 각각 다른 곳을 가리키고 있을 수 있다.

그래서 만약 CPU 코어가 3개가 있다고 한다면, 각 CPU코어의 PC는 main\( \)과 f1\( \)과 f2\( \)를 가리키고 있을 수 있다 \(CPU dispatched for child & starts here\). 그렇게 만들어진 child를 커널 스레드라 한다. 이는 child들이 커널 코드를 실행\(execute\)하고 있기 때문이다. 대부분의 경우 이런 함수들은 서버\(server\) 혹은 데몬\(daemon\)이다.

서버와 데몬의 알고리즘은 기본적으로 무한 루프\(endless loop\)라고 우린 배웠다. 또한 서버와 데몬은 대부분의 시간을 자면서\(sleep\) 보낸다. 그러다 요청\(request\)이 오면 깨어나 그 작업을 처리해주고 또 잔다. 네트워크와 관련된 작업을 처리하는 데몬이라면 네트워크 서버라고 부를 수 있고, 만약 프린트 요청을 기다리고 있다면 프린트 서버라고 할 수 있다.

결국 커널 스레드는 커널 프로세스가 clone\( \)을 호출해서 light weight overhead로 child를 만들어준 것이다. 또한 커널 메모리 영역과 코드를 똑같이 접근하고, 커널 코드를 실행한다. 당연하게도 커널 스레드는 커널 영역에만 존재한다. 많은 데몬\(웹서버, 프린트 등\)들이 커널 스레드이다.

![](/assets/Chapter 5_1.PNG)

CPU가 여러개 있고 CPU 마다 PC\(Program Counter\)를 가지고 있다. 지금은 PC가 커널을 가리키고 있다. 여기서 커널이 clone\( \)을 통하여 스레드 2개를 만들어줬다고 가정해보자. CPU \#2에 할당된 것은 프린트 데몬\(서버\)이고, \#3에 할당된 것은 PageFault 데몬이다. 알다시피 스레드는 위 템플릿의 우측에 해당하는 Task basic info 파트만 복사를 하고 나머진 부모 프로세스와 공유를 한다.

Task basic info 안에는 state vector save area가 존재하기 때문에 각 스레드마다 별도의 Program Counter와 Stack Pointer를 갖고 있을 수 있는 것이다. 각 스레드가 각자의 Stack을 갖고 있기 때문에 개별적으로 커널 내의 다른 함수들을 호출하면서 실행될 수가 있다.

## Process State

---

프로세스의 상태에는 ready, running, waiting이 존재한다. running은 프로세스 입장에서는 최상의 상태이며, running 중 Disk I/O를 요구하는 사건이 발생하면 CPU가 해당 프로세스의 상태를 waiting으로 바꾼다. waiting의 경우 시그널의 상황에 따라 2가지의 반응이 있을 수 있는데 이 부분은 중요한 내용은 아니므로 넘어가도록 한다.

![](/assets/Chapter 5_2.PNG)

I/O가 끝나고 상태는 wait에서 ready로 넘어가게 된다\(CPU는 항상 바쁘다\). I/O가 끝나고 ready list에 참여해서 기다리다 보면 자신의 차례가 올 것이다. 차례가 오는 것을 Scheduler dispatches라고 표현한다. dispatch 과정을 상세하게 풀어보자면, context\_switch\( \)의 동작으로 설명할 수 있다. 첫번째로 현재 사용중이던 프로세스의 state vector를 저장한다. 그리고나서 run하고 싶은 프로세스의 state vector를 CPU에 로드한 후, Program Counter가 가리키는 곳으로 가는 것이 dispatch의 과정이다.

CPU가 주어지면 어느 정도의 시간\(time slice\)만큼만 동작하고, 시간이 끝나면 다시 ready list로 가는 구조인데, 일단 프로세스가 성공적으로 exit\( \)했다고 가정해보자. 프로세스가 exit\( \)을 하게 되면 zombie 상태가 된다. 좀비 상태라는 것은 a.out도 날라가고 file도 전부 closed되고 메인 메모리도 다 뺐기고, PCB만 남은 상태를 의미한다. 왜 PCB가 남아있는 것일까? PCB를 없애면, 얘가 exit\( \)하면 이제 끝이야.parent가 지금까지 기다리고 있었으면, parent가 깨어나 CPU를 run하겠지. 이 parent는 자기가 잘 동안 child가 뭘 했는지, 디스크와 CPU를 얼마나 썼는지, 제대로 끝났는지 등에 대한 내용이 PCB에 담겨 있다. 따라서 parent가 말소시키는 것이 맞다. parent가 말소시킬 때까지는 zombie상태인 것이다. 따라서 맨 위의 프로세스는 자식 프로세스들이 사용한 모든 자원을 전부 파악할 수 있어야 한다.



## Kernel Scheduling \(커널 스케쥴링\)

---

![](/assets/Chapter 5_3.PNG)

리눅스에서는 어떤 프로세스가 다음에 실행될 프로세스일까? 물론 priority\(우선순위\)가 가장 큰 프로세스가 실행될 것이다. 하지만 time slice를 가지고 있는지도 반드시 확인해야 한다. 타임 슬라이스\(time slice\)에 대한 설명은 아래 템플릿을 보면서 살펴보도록 한다.

![](/assets/Chapter 5_4.PNG)

먼저 위쪽 네모박스 안의 내용을 살펴보자. CPU가 어떤 프로세스에게 할당될 때는 일종의 시간제한이 있게 된다. 위 예시에서는 100ms라고 되어 있다. 하지만 안타깝게도 이마저도 못쓰게 되는 경우가 발생할 수 있다. 현재 프로세스보다도 더 급한 작업이 요구되었을 때, CPU를 또다시 빼앗길 수 있다. 위 네모박스 안에서는 20ms를 사용하다가 CPU를 뺏겨버렸고 남은 80ms는 추후에 다시 CPU를 받았을 때 사용해야 한다. 여기서 남은 80ms를 remaining timeslice라고 한다. 

즉, 리눅스에서 프로세스가 CPU를 차지하기 위해서는 우선순위가 높아야 하고 남은 타임슬라이스가 0보다 커야 한다. 아래 템플릿을 보면서 스케쥴링이 정확하게 어떻게 이루어지는지 알아보자. 맨 위의 레디큐\(Ready Queue\)를 살펴보자. 레디큐에는 PCB가 여러개 들어 있다. 바로 실행\(run\)할 수 있는 작업들이 쭈욱 연결되어 있는 것이다. 이런 구조에서의 문제점은 멀티 프로세서 시스템이 되서 CPU의 갯수가 증가하게 되면 연결된 머신의 수에 따라 레디큐에 연결되는 PCB도 기하급수적으로 많아질 것이라는 데 있다. 500개의 프로세스가 돌고 있다고 가정한다면, context\_switch\( \)를 발생할 때마다 이 레디큐를 전부 뒤져서 우선순위가 높은 프로세스를 골라내야 하는데, 작업이 상당히 비효율적이라는 생각이 든다.

![](/assets/Chapter 5_5.PNG)

그래서 이번에는 중간에 있는 구조로 설계를 해 보았다. 하나의 레디큐로 두는 것은 탐색하는데 비효율적이라고 생각으로부터 나온 설계다. 높은 우선순위와 낮은 우선순위를 가지는 두 개의 큐를 제작했다. 하나의 큐 보다는 확실히 효율적이겠지만, 이마저도 만족스럽지 않기에 위 템플릿의 맨 아래와 같은 설계를 해봤다. 좀 더 분류를 세분화해서 여러 개의 큐를 만들었다. 각 큐는 PCB를 가리키는 포인터로 이루어져 있다.

하지만 주황색으로 구현된 큐를 보니 중간 중간 비어 있는 큐\(2번과 4번 큐\)도 보인다. 이러한 큐까지 탐색할 필요는 없으니 좀 더 효율적으로 탐색을 해볼 수 있지 않을까? 라는 생각을 할 수 있다. 따라서 아래 템플릿과 같이 해당 우선순위에 해당하는 큐가 비었는지 안 비었는지를 체크할 수 있는 비트 배열을 하나 더 두게 된다.

![](/assets/Chapter 5_6.PNG)

좌측에는 바이너리 배열이 하나 있는데, 0은 해당 인덱스의 포인터를 따라가면 해당 인덱스의 큐가 비어 있다는 뜻이고 1이라면 해당 인덱스의 큐에 내용물이 있다는 뜻이다. 유닉스에서는 이 바이너리 배열을 비트맵이라 부른다. 이렇게 비트로된 배열을 사용함으로써 탐색 속도가 향상될 수 있다. 이 비트맵의 인덱스가 얼마나 존재하는지가 시스템에서 다루는 난이도가 얼마나 세분화되어 있는지를 나타낸다. 우측에는 큐로 이루어진 배열이 존재한다. 해당 큐의 각 내용물은 PCB로 이루어져 있다.

위 템플릿의 맨 밑을 보면 구조체가 하나 존재한다. 그 구조체 안에는 비트맵과 큐 배열이 존재한다. 멀티 프로세서 시스템에서 CPU가 10개 있다고 한다면, 이 구조체가 각 CPU마다 존재한다고 생각하면 된다. 비트맵과 큐 배열을 함께 포함하고 있는 구조체가 바로 priority array \(우선순위 배열\) 이다.

![](/assets/Chapter 5_7.PNG)

CPU 스케쥴러가 context\_switch\( \)가 일어나야 할 때마다, 즉 레디큐에서 우선순위가 가장 높은 프로세스를 뽑기 위해서 해야할 작업은 1. 비트맵을 스캔한다. 2. 0이 아니라면 작업내역을 순회한다. 0이 아닌 비트맵이 있다면 포인터를 따라가서 해당 큐의 작업 내역을 실행하면 된다.





